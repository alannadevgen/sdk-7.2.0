# coding: utf-8

"""
    Tenant API

    Tenant API

    The version of the OpenAPI document: 0.0.1
    Contact: abc@layer.fr
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from typing import Any, ClassVar, Dict, List, Optional, Union
from pydantic import BaseModel, StrictStr
try:
    from typing import Self
except ImportError:
    from typing_extensions import Self

class Options(BaseModel):
    """
    Options
    """ # noqa: E501
    env: Optional[Dict[str, StrictStr]] = None
    docker_image: Optional[StrictStr] = None
    instance_type: Optional[StrictStr] = None
    type: Optional[StrictStr] = None
    __properties: ClassVar[List[str]] = ["env", "docker_image", "instance_type", "type"]

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }


    # JSON field name that stores the object type
    __discriminator_property_name: ClassVar[List[str]] = 'type'

    # discriminator mappings
    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
        'airflow': 'AirflowOptions','bash': 'BashOptions','dask': 'DaskOptions','database-migration': 'DatabaseMigrationOptions','dbt': 'DbtOptions','flink': 'FlinkOptions','hadoop': 'HadoopOptions','knime': 'KnimeOptions','lowcode': 'LowCodeOptions','mxnet': 'MXNetOptions','python': 'PythonOptions','pytorch': 'PyTorchOptions','ray': 'RayOptions','sas': 'SASOptions','spark': 'SparkOptions','tensorflow': 'TensorflowOptions','xgboost': 'XgboostOptions'
    }

    @classmethod
    def get_discriminator_value(cls, obj: Dict) -> str:
        """Returns the discriminator value (object type) of the data"""
        discriminator_value = obj[cls.__discriminator_property_name]
        if discriminator_value:
            return cls.__discriminator_value_class_map.get(discriminator_value)
        else:
            return None

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Union[Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self]:
        """Create an instance of Options from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={
            },
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Union[Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self, Self]:
        """Create an instance of Options from a dict"""
        # look up the object type based on discriminator mapping
        object_type = cls.get_discriminator_value(obj)
        if object_type:
            klass = globals()[object_type]
            return klass.from_dict(obj)
        else:
            raise ValueError("Options failed to lookup discriminator value from " +
                             json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
                             ", mapping: " + json.dumps(cls.__discriminator_value_class_map))

from graalsystems.models.airflow_options import AirflowOptions
from graalsystems.models.bash_options import BashOptions
from graalsystems.models.dask_options import DaskOptions
from graalsystems.models.database_migration_options import DatabaseMigrationOptions
from graalsystems.models.dbt_options import DbtOptions
from graalsystems.models.flink_options import FlinkOptions
from graalsystems.models.hadoop_options import HadoopOptions
from graalsystems.models.knime_options import KnimeOptions
from graalsystems.models.low_code_options import LowCodeOptions
from graalsystems.models.mx_net_options import MXNetOptions
from graalsystems.models.py_torch_options import PyTorchOptions
from graalsystems.models.python_options import PythonOptions
from graalsystems.models.ray_options import RayOptions
from graalsystems.models.sas_options import SASOptions
from graalsystems.models.spark_options import SparkOptions
from graalsystems.models.tensorflow_options import TensorflowOptions
from graalsystems.models.xgboost_options import XgboostOptions
# TODO: Rewrite to not use raise_errors
Options.model_rebuild(raise_errors=False)

